{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN74pUWY2p0v/4a6UhrZXzj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstraBert/SacCerML/blob/main/SacCerML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "5U9Z6d5fL65q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install biopython==1.81"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Dl12G6MDF3",
        "outputId": "58c5c014-e406-44e3-acad-61246ce2f0c8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython==1.81 in /usr/local/lib/python3.10/dist-packages (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython==1.81) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import BiopythonWarning\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore', BiopythonWarning)\n",
        "    from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "    from Bio.SeqUtils.CheckSum import crc32\n",
        "    from Bio.SeqUtils.CodonUsage import CodonAdaptationIndex\n",
        "    from Bio.SeqUtils.CodonUsageIndices import SharpEcoliIndex\n",
        "    from Bio.SeqUtils import six_frame_translations\n",
        "    from Bio.Seq import Seq\n",
        "    from Bio import SeqIO\n",
        "import gzip\n",
        "from math import floor\n"
      ],
      "metadata": {
        "id": "J-QfbIE0MdRH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CSV structure: ORF_TYPE,CAI,CHECKSUM,HIDROPHOBICITY,ISOELECTRIC,AROMATIC,INSTABLE,MW,HELIX,TURN,SHEET,MOL_EXT_RED,MOL_EXT_OX\n",
        "def load_data(infile):\n",
        "    \"\"\"Load data from infile if it is in fasta format (after having unzipped it, if it is zipped)\"\"\"\n",
        "    if infile.endswith(\".gz\"):  # If file is gzipped, unzip it\n",
        "        y = gzip.open(infile, \"rt\", encoding=\"latin-1\")\n",
        "        # Read file as fasta if it is fasta\n",
        "        if infile.endswith(\".fasta.gz\") or infile.endswith(\".fna.gz\") or infile.endswith(\".fas.gz\") or infile.endswith(\".fa.gz\"):\n",
        "            records = SeqIO.parse(y, \"fasta\")\n",
        "            sequences = {}\n",
        "            for record in records:\n",
        "                sequences.update({str(record.id): str(record.seq)})\n",
        "            y.close()\n",
        "            return sequences\n",
        "        else:\n",
        "            y.close()\n",
        "            raise ValueError(\"File is the wrong format\")\n",
        "    # Read file directly as fasta if it is a not zipped fasta: handle also more uncommon extensions :-)\n",
        "    elif infile.endswith(\".fasta\") or infile.endswith(\".fna\") or infile.endswith(\".fas\") or infile.endswith(\".fa\"):\n",
        "        with open(infile, \"r\") as y:\n",
        "            records = SeqIO.parse(y, \"fasta\")\n",
        "            sequences = {}\n",
        "            for record in records:\n",
        "                sequences.update({str(record.id): str(record.seq)})\n",
        "            y.close()\n",
        "            return sequences\n",
        "    else:\n",
        "        raise ValueError(\"File is the wrong format\")"
      ],
      "metadata": {
        "id": "AkWGseg6MhF1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cai(dna,index=SharpEcoliIndex):\n",
        "    cai = CodonAdaptationIndex()\n",
        "    cai.set_cai_index(index)\n",
        "    if len(dna) % 3 == 0:\n",
        "        a = cai.cai_for_gene(dna)\n",
        "    else:\n",
        "        six_translated = six_frame_translations(dna)\n",
        "        n = six_translated.split(\"\\n\")\n",
        "        frames = {\"0;F\": n[5], \"1;F\": n[6], \"2;F\": n[7],\"0;R\": n[12], \"1;R\": n[11], \"2;R\": n[10]}\n",
        "        ind = 0\n",
        "        for i in list(frames.keys()):\n",
        "            k = frames[i].replace(\" \",\"\")\n",
        "            if \"M\" in k and \"*\" in k:\n",
        "                if i.split(\";\")[0]==\"F\" and k.index(\"M\") < k.index(\"*\"):\n",
        "                    if len(k) <= len(dna)/3:\n",
        "                        ind = int(i.split(\"\")[0])\n",
        "                        break\n",
        "                elif i.split(\";\")[0]==\"R\" and k.index(\"M\") > k.index(\"*\"):\n",
        "                    if len(k) <= len(dna)/3:\n",
        "                        ind = len(dna) - int(i.split(\"\")[0])\n",
        "                        break\n",
        "        if ind == 0:\n",
        "            cods = 3*floor(len(dna)/3)\n",
        "            dna = dna[:cods]\n",
        "            a = cai.cai_for_gene(dna)\n",
        "        elif 1 <= ind <= 2:\n",
        "            if len(dna[ind:])%3==0:\n",
        "                dna = dna[ind:]\n",
        "            else:\n",
        "                cods = 3*floor((len(dna)-ind)/3)\n",
        "                dna = dna[ind:cods+ind]\n",
        "                a = cai.cai_for_gene(dna)\n",
        "        else:\n",
        "            if len(dna[:ind])%3==0:\n",
        "                dna = dna[ind:]\n",
        "            else:\n",
        "                cods = 3*floor((len(dna)-ind)/3)\n",
        "                dna = dna[:cods]\n",
        "                a = cai.cai_for_gene(dna)\n",
        "    return a\n",
        "\n",
        "\n",
        "def checksum(dna):\n",
        "    return crc32(dna)\n",
        "\n",
        "\n",
        "def hidrophobicity(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    hydrophobicity_score = ProteinAnalysis(protein_sequence).gravy()\n",
        "    return hydrophobicity_score\n",
        "\n",
        "def isoelectric_pt(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    isoelectric = ProteinAnalysis(protein_sequence).isoelectric_point()\n",
        "    return isoelectric\n",
        "\n",
        "def aromatic(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    arom = ProteinAnalysis(protein_sequence).aromaticity()\n",
        "    return arom\n",
        "\n",
        "\n",
        "def instable(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    inst = ProteinAnalysis(protein_sequence).instability_index()\n",
        "    return inst\n",
        "\n",
        "def weight(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    wgt = ProteinAnalysis(protein_sequence).molecular_weight()\n",
        "    return wgt\n",
        "\n",
        "def sec_struct(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    second_struct = ProteinAnalysis(protein_sequence).secondary_structure_fraction()\n",
        "    return \",\".join([str(s) for s in second_struct])\n",
        "\n",
        "def mol_ext(dna):\n",
        "    protein_sequence = str(Seq(dna).translate())\n",
        "    protein_sequence = protein_sequence.replace(\"*\",\"\")\n",
        "    molar_ext = ProteinAnalysis(protein_sequence).molar_extinction_coefficient()\n",
        "    return \",\".join([str(s) for s in molar_ext])\n"
      ],
      "metadata": {
        "id": "DnxoWuKPMlk9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install orfipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prjaX3Xgdb0A",
        "outputId": "85781320-e5c2-406c-b501-6fc4db15b710"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting orfipy\n",
            "  Downloading orfipy-0.0.4.tar.gz (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from orfipy) (3.0.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from orfipy) (5.9.5)\n",
            "Collecting pyfastx (from orfipy)\n",
            "  Downloading pyfastx-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from orfipy)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from orfipy)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: orfipy\n",
            "  Building wheel for orfipy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orfipy: filename=orfipy-0.0.4-cp310-cp310-linux_x86_64.whl size=551358 sha256=b1e7f616b68f68ed375ece8ce0e78d2048d99f2e31f9bf25156e42baada24898\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/09/ab/cdd01e13be3152391ec0439bbffaa2c870e8f3badc88674b56\n",
            "Successfully built orfipy\n",
            "Installing collected packages: pyfastx, pyahocorasick, colorama, orfipy\n",
            "Successfully installed colorama-0.4.6 orfipy-0.0.4 pyahocorasick-2.0.0 pyfastx-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from orfipy_core import orfs\n",
        "import sys\n",
        "\n",
        "def longest_orf(coding):\n",
        "    keys_M_starting = [key for key in list(coding.keys()) if str(Seq(coding[key]).translate()).startswith(\"M\")]\n",
        "    M_starting = [seq for seq in list(coding.values()) if str(Seq(seq).translate()).startswith(\"M\")]\n",
        "    lengths = [len(seq) for seq in M_starting]\n",
        "    max_ind = lengths.index(max(lengths))\n",
        "    return {keys_M_starting[max_ind]: M_starting[max_ind]}\n",
        "\n",
        "\n",
        "def predict_orf(seq,minlen=45,maxlen=18000,longest_M_starting_orf_only=True):\n",
        "    ls = orfs(seq,minlen=minlen,maxlen=maxlen)\n",
        "    coding = {}\n",
        "    count = 0\n",
        "    for start,stop,strand,description in ls:\n",
        "        count+=1\n",
        "        if start < stop:\n",
        "            coding.update({f\"ORF.{count}\": seq[int(start):int(stop)]})\n",
        "        else:\n",
        "            coding.update({f\"ORF.{count}\": str(Seq(seq[int(stop):int(start)]).reverse_complement())})\n",
        "    if longest_M_starting_orf_only:\n",
        "        warnings.warn(\"\\n---------------------------\\nWarning: option longest_M_starting_orf_only is set to True and thus you will get only the longest M-starting ORF; to get all the ORFs, set it to False\\n---------------------------\\n\")\n",
        "        return longest_orf(coding)\n",
        "    return coding"
      ],
      "metadata": {
        "id": "54OgjX07duZ6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dna(fasta_file, longest_M_starting_orf_only):\n",
        "    fas = load_data(fasta_file)\n",
        "    seqs = [seq for seq in list(fas.values())]\n",
        "    heads = [seq for seq in list(fas.keys())]\n",
        "    data = {}\n",
        "    proteins = {}\n",
        "    for i in range(len(seqs)):\n",
        "        coding = predict_orf(seqs[i],longest_M_starting_orf_only=longest_M_starting_orf_only)\n",
        "        open_reading_frames = list(coding.keys())\n",
        "        for key in open_reading_frames:\n",
        "            head = f\"{heads[i]}.{key}\"\n",
        "            proteins.update({head: str(Seq(coding[key]).translate())})\n",
        "            cai = calculate_cai(coding[key])\n",
        "            cksm = checksum(coding[key])\n",
        "            hydr = hidrophobicity(coding[key])\n",
        "            isl = isoelectric_pt(coding[key])\n",
        "            arm = aromatic(coding[key])\n",
        "            inst = instable(coding[key])\n",
        "            mw = weight(coding[key])\n",
        "            se_st = sec_struct(coding[key]).split(\",\")\n",
        "            se_st1 = se_st[0]\n",
        "            se_st2 = se_st[1]\n",
        "            se_st3 = se_st[2]\n",
        "            me = mol_ext(coding[key]).split(\",\")\n",
        "            me1 = me[0]\n",
        "            me2 = me[1]\n",
        "            n = pd.DataFrame({\"CAI\": [cai], \"CHECKSUM\": [cksm], \"HIDROPHOBICITY\": [hydr], \"ISOELECTRIC\": [isl],\"AROMATIC\": [arm],\"INSTABLE\": [inst], \"MW\": [mw], \"HELIX\": [se_st1], \"TURN\": [se_st2], \"SHEET\": [se_st3],\"MOL_EXT_RED\": [me1], \"MOL_EXT_OX\": [me2]})\n",
        "            data.update({head: n})\n",
        "    return data, proteins\n"
      ],
      "metadata": {
        "id": "njo6hsOyMsYe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, you will have to load the following files from the data folder:\n",
        "- scerevisiae.csv\n",
        "- test.fasta"
      ],
      "metadata": {
        "id": "MIXbQffC1Atn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "csv = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "BYk4aBS7M0Yo",
        "outputId": "3568bc2c-9b5d-4c75-a536-fed82420b6f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9130210-18f2-4234-8e62-37e3d0bfe47f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9130210-18f2-4234-8e62-37e3d0bfe47f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving scerevisiae.csv to scerevisiae.csv\n",
            "Saving test.fasta to test.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading data...\")\n",
        "# Load the data from the CSV file\n",
        "data = pd.read_csv('scerevisiae.csv')\n",
        "print(\"Loaded data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-qTw-HPNXU7",
        "outputId": "e43670f2-4c78-4749-9c31-0d5d4ffd9921"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating training and test data...\")\n",
        "# Features\n",
        "X = data.iloc[:, 1:]\n",
        "\n",
        "# Labels\n",
        "y = data['ORF_TYPE']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Generated training and test data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTahl4Z5NYil",
        "outputId": "7c9f8d8a-42db-4449-e415-0eaf2ea1f062"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training and test data...\n",
            "Generated training and test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building and training the model...\")\n",
        "# Create and train the Decision Tree classifier\n",
        "model = DecisionTreeClassifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcjqNaLkNdp3",
        "outputId": "1af13fc7-4704-4dae-9392-bae52b867d76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building and training the model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.fit(X, y)\n",
        "print(\"Built and trained the model... Now predicting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_gCRZPGNix-",
        "outputId": "a7194b61-8738-4cde-ce43-85381393d826"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built and trained the model... Now predicting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9K-n9k8TkHZ",
        "outputId": "bc97e724-8cb4-471e-dcca-1f87a05bdf6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9992559523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_genes(infile, longest_M_starting_orf_only, model=model):\n",
        "    X, proteins = process_dna(infile,longest_M_starting_orf_only)\n",
        "    headers = list(X.keys())\n",
        "    predictions = []\n",
        "    for x in list(X.values()):\n",
        "      p = model.predict(x)\n",
        "      predictions.append(p)\n",
        "    for i in range(len(predictions)):\n",
        "        print(f\"{headers[i]} protein sequence is\\n{proteins[headers[i]]}\\nand is predicted as {predictions[i][0]}\\n\")"
      ],
      "metadata": {
        "id": "vxsNLepSOaLG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import BiopythonWarning\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore', BiopythonWarning)\n",
        "    warnings.simplefilter('ignore', UserWarning)\n",
        "    inf = \"test.fasta\"\n",
        "    predict_genes(inf, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87wJ8HJoOlt2",
        "outputId": "b6cc2066-00f2-4180-96ca-8c056d0fdad8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YGR292w.ORF.7 protein sequence is\n",
            "MTISDHPETEPKWWKEATIYQIYPASFKDSNNDGWGDLKGITSKLQYIKDLGVDAIWVCPFYDSPQQDMGYDISNYEKVWPTYGTNEDCFELIDKTHKLGMKFITDLVINHCSTEHEWFKESRSSKTNPKRDWFFWRPPKGYDAEGKPIPPNNWKSFFGGSAWTFDETTNEFYLRLFASRQVDLNWENEDCRRAIFESAVGFWLDHGVDGFRIDTAGLYSKRPGLPDSPIFDKTSKLQHPNWGSHNGPRIHEYHQELHRFMKNRVKDGREIMTVGEVAHGSDNALYTSAARYEVSEVFSFTHVEVGTSPFFRYNIVPFTLKQWKEAIASNFLFINGTDSWATTYIENHDQARSITRFADDSPKYRKISGKLLTLLECSLTGTLYVYQGQEIGQINFKEWPIEKYEDVDVKNNYEIIKKSFGKNSKEMKDFFKGIALLSRDHSRTPMPWTKDKPNAGFTGPDVKPWFLLNESFEQGINVEQESRDDDSVLNFWKRALQARKKYKELMIYGYDFQFIDLDSDQIFSFTKEYEDKTLFAALNFSGEEIEFSLPREGASLSFILGNYDDTDVSSRVLKPWEGRIYLVK\n",
            "and is predicted as Verified_ORF\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
